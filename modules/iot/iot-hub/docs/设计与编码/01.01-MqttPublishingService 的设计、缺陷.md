MqttPublishingService 的设计、缺陷



## 问： 消息发布（MqttPublishingService）设计有什么缺陷，不优雅的地方，尤其是消息连续套用Abp的事件总线 

AI 深度思考：

```plantext
用户现在问的是 MqttPublishingService 里消息连续套用 ABP 事件总线的缺陷和不优雅的地方，首先得先拆解这个场景的核心问题，然后从架构、性能、可维护性、可靠性、调试排查、资源管控这些维度分析，还要结合 MQTT 消息发布的特性（高并发、实时性）来谈。
首先，先明确核心场景：MQTT 设备上报消息→MqttPublishingService 接收→连续发布多个 ABP 分布式事件（比如先发布 “原始数据接收事件”，再发布 “物模型解析事件”，再发布 “数据存储事件”），这种连续套用的问题。
第一步，先梳理缺陷分类，比如：
架构层面：职责边界模糊 + 事件耦合严重
ABP 事件总线（尤其是分布式）设计初衷是解耦跨模块通信，但连续套用会让 “MQTT 消息发布” 这个核心流程被拆成多个事件依赖，形成 “事件链”，模块间从 “解耦” 变成 “隐式强依赖”。比如上游事件失败会导致下游全卡，而且事件的触发顺序、依赖关系没有显性约束，比如必须先解析再存储，但代码里只是连续 Publish，没有保障，架构上不优雅，违背 “单一职责” 和 “最小事件粒度” 原则。
另外，MqttPublishingService 本应聚焦 “MQTT 消息的接收 / 转发 / 基础校验”，但连续发布事件会让它变成 “事件调度中心”，职责膨胀，后续改一个流程要改多个事件的发布逻辑，维护成本高。
性能与实时性问题（MQTT 场景核心痛点）
分布式事件总线（比如基于 RabbitMQ/Kafka）本身有网络 IO、序列化 / 反序列化开销，连续发布多个事件会叠加开销，对于 MQTT 高并发（比如每秒数千条消息）场景，单条消息的处理耗时被放大，容易导致 MQTT 客户端的 QoS 重传（比如 QoS1 的消息因为处理慢超时重传），甚至消息堆积。
批量处理的抵消效应：之前提到 MqttPublishingService 有批量发布优化，但连续事件会让批量逻辑失效 —— 比如批量攒了 100 条 MQTT 消息，每条要发 3 个事件，相当于批量后还要发 300 个事件，事件总线的批量能力（如果有的话）没利用，反而加剧性能损耗。
资源竞争：连续发布事件会频繁占用事件总线的连接 / 线程池，尤其是 ABP 默认的事件总线如果是基于内存（本地），连续发布会占用线程池；如果是分布式，会频繁创建网络请求，导致端口 / 连接数耗尽。
可靠性与一致性问题
缺乏事务性保障：ABP 分布式事件总线默认不支持 “事件发布事务”，比如连续发布 3 个事件，前 2 个成功，第 3 个失败，会导致数据不一致（比如解析事件成功但存储事件失败，数据丢了）。而 MQTT 消息通常有 QoS 要求，这种不一致会导致设备侧认为消息已送达，但平台侧数据不完整，违背 MQTT 的可靠性承诺。
重试机制冲突：Polly 的熔断 / 重试是加在 MqttPublishingService 的事件发布上，但连续事件的重试是独立的 —— 比如第一个事件重试成功，第二个重试失败，最终状态混乱；而且 ABP 事件总线的重试（如果配置）和 Polly 重试叠加，导致重复处理，比如重复解析、重复存储，出现脏数据。
可维护性与调试成本高（不优雅的核心体现）
隐式流程难以追踪：连续发布事件让 “MQTT 消息从接收→解析→存储” 的流程变成 “黑盒”，比如要查一条消息为什么没存储，需要从 MqttPublishingService 的事件发布→事件总线→事件处理器→下游模块全链路排查，日志分散（事件发布日志、事件处理日志、总线传输日志），定位问题要翻多个服务的日志，调试效率极低。
事件命名 / 粒度不规范：连续套用容易出现 “粒度混乱”，比如有的事件是 “原始数据接收”（粗粒度），有的是 “温度字段解析”（细粒度），连续发布时粒度没有统一，后续新增字段要加新事件，事件数量爆炸，命名混乱（比如 ThingModelParsedEvent、RawDataReceivedEvent、DataSaveEvent，没有统一规范），代码可读性差。
扩展困难：如果要新增一个 “告警触发” 步骤，需要在事件链里加一个新事件发布，要修改 MqttPublishingService 的代码，违背 “开闭原则”；而且如果下游模块修改了事件消费逻辑，上游 MqttPublishingService 可能要适配，耦合又回来了。
资源管控与熔断策略失效
之前提到用 Polly 做熔断，但连续事件的熔断是独立的 —— 比如针对 “存储事件” 的熔断触发了，但 “解析事件” 还在发布，导致部分事件堆积，资源被无效占用；而且 Polly 的策略如果是加在单个事件发布上，连续发布时策略无法全局管控，比如总事件发布 QPS 超限，但单个事件的熔断阈值没到，还是会过载。
内存泄漏风险：连续发布事件时，如果事件对象没有及时释放（比如包含大的原始 MQTT 消息体），加上高并发下的对象创建速度快，容易导致 GC 压力大，甚至内存泄漏，尤其是 ABP 事件总线的本地事件会缓存事件对象直到处理完成。
违背 ABP 事件总线的最佳实践
ABP 官方建议 “事件应是‘通知型’而非‘命令型’”，连续发布事件容易把 “命令”（比如 “去解析这条数据”“去存储这条数据”）包装成事件，事件变成了 “强制执行的指令”，而非 “状态变更的通知”。比如 MQTT 消息发布后，发布 “解析事件” 本质是命令下游解析，而不是通知下游 “数据已接收，可以解析”，违背设计初衷，不优雅。
分布式事件适合 “跨微服务 / 跨模块的异步通知”，但如果解析、存储都在同一个微服务内，连续发布分布式事件完全没必要，应该用本地方法调用，反而更高效，这是过度设计，不优雅。
然后，还要补充 “不优雅的具体代码表现”，比如：
示例代码（反例）：
public async Task PublishMqttMessageAsync (MqttApplicationMessage message)
{
// 连续发布 3 个事件，典型的不优雅写法
await _distributedEventBus.PublishAsync (new RawDataReceivedEvent (message));
var parsedData = _thingModelParser.Parse (message);
await _distributedEventBus.PublishAsync (new ThingModelParsedEvent (parsedData));
await _distributedEventBus.PublishAsync (new DataSaveEvent (parsedData));
}
这种代码的问题：
无异常处理隔离：一个事件发布失败，后续都失败，没有兜底；
无顺序保障：如果事件总线是异步的，可能下游处理器先收到 DataSaveEvent 再收到 ThingModelParsedEvent；
无资源管控：连续 Publish 没有限流，高并发下直接打满事件总线。
接下来，还要总结优化方向（这样回答更完整），比如：
重构事件粒度与职责：
合并冗余事件：将 “原始数据接收 + 解析 + 存储” 的连续事件合并为一个 “MQTT 消息处理完成事件”（或按业务域拆分，而非流程步骤拆分）；
区分本地 / 分布式事件：同微服务内的解析、存储用本地方法调用，跨微服务的通知用分布式事件，避免过度使用分布式事件。
引入事件编排 / 工作流：
用状态机（比如 Stateless）或工作流引擎（比如 ABP Workflow）管理事件触发顺序，显性化流程依赖，而非连续 Publish。
事务性事件发布：
使用 ABP 的 “Unit of Work + 事件总线事务”（ABP 支持在 UOW 内发布事件，UOW 提交后才发布），或基于 Outbox 模式（事务性发件箱）保障事件发布的一致性，避免部分成功。
批量事件发布优化：
对同一类型的事件做批量 Publish，比如攒 100 条 ParsedEvent 再批量发布，而非单条连续发布。
职责边界重构：
MqttPublishingService 只负责 MQTT 消息的接收、校验、基础格式化，然后发布一个 “MQTT 原始消息可用事件”，下游模块订阅后自行处理解析、存储，而非上游连续发布多个事件。
可观测性增强：
给每个事件添加统一的 TraceId（关联 MQTT 消息的 MessageId），全链路日志串联，方便排查。
现在要把这些思路组织成清晰的回答，先讲核心缺陷（分维度，结合 MQTT 场景和 ABP 事件总线的特性），再讲不优雅的代码表现，最后补充优化方向，确保逻辑连贯，贴合用户的问题（尤其是连续套用事件总线的问题）。
```



## AI答

### 一、MqttPublishingService 中「连续套用 ABP 事件总线」的核心缺陷

ABP 事件总线（尤其是分布式事件总线）的设计初衷是**跨模块 / 跨服务的解耦式通知**，但在 MqttPublishingService 中「连续发布多个事件」的做法，会从性能、可靠性、可维护性等维度暴露严重缺陷，且违背事件总线的设计原则，具体如下：

#### 1. 架构层面：职责膨胀 + 事件链隐式强依赖（最核心的不优雅）

- **职责边界模糊**：MqttPublishingService 的核心职责应是「MQTT 消息的接收、基础校验、批量转发」，但连续发布事件会让它沦为「事件调度中心」—— 既要处理 MQTT 协议层逻辑，又要管控业务事件的触发顺序（解析→存储→告警等），违背「单一职责原则」。后续修改任意一个业务步骤（比如新增 “数据脱敏”），都需要修改该服务的事件发布逻辑，耦合度反而比直接调用方法更高。
- 事件链形成隐式强依赖：连续发布的事件会形成「上游事件→下游事件」的链式依赖（如 `RawDataReceivedEvent`→ `ThingModelParsedEvent`→ `DataPersistEvent`），但这种依赖是隐式且无约束的：
  - 代码中仅通过 `await _eventBus.PublishAsync()` 连续调用保障顺序，无显性的流程约束（比如事件 B 必须等待事件 A 处理完成）；
  - 若某一个事件发布失败（如网络波动导致分布式事件发送超时），会导致后续所有事件中断，且无法感知 “哪一环断了”，从 “解耦” 变成 “链式故障扩散”。

#### 2. 性能层面：叠加开销 + 高并发场景下的性能雪崩（MQTT 场景的致命缺陷）

MQTT 消息的核心诉求是**高并发、低延迟**（比如工业场景每秒数千条设备上报消息），但连续发布事件会放大性能损耗：

- **分布式事件的开销叠加**：ABP 分布式事件总线（如基于 RabbitMQ/Kafka）本身包含「序列化 / 反序列化 + 网络 IO + 消息队列写入」三重开销，单条 MQTT 消息连续发布 3 个事件，相当于单条消息的处理耗时 ×3；
- 批量优化被抵消：即便 MqttPublishingService 做了 “批量攒批发布 MQTT 消息” 的优化，但每条消息要触发多事件，批量后事件总数呈倍数增长（比如批量 100 条 MQTT 消息 → 300 个事件），事件总线的处理能力会成为瓶颈，最终导致：
  - MQTT 客户端侧：QoS 1/2 的消息因处理超时触发重传，加剧消息堆积；
  - 服务侧：线程池被事件发布的异步操作占满，MQTT 连接处理线程饥饿。
- **本地事件也存在线程开销**：即便使用 ABP 本地事件总线（内存级），连续发布事件也会频繁占用线程池，高并发下引发线程上下文切换飙升。

#### 3. 可靠性层面：无事务保障 + 重试冲突（数据一致性风险）

- **事件发布无原子性**：ABP 事件总线（尤其是分布式）默认不支持「批量事件的事务性发布」—— 比如连续发布 3 个事件，前 2 个成功、第 3 个失败，会导致 “数据解析完成但未存储”“数据存储完成但未告警” 等不一致场景，而 MQTT 消息的 QoS 机制仅保障 “消息送达平台”，无法保障 “业务流程完成”，最终设备侧认为消息已上报，平台侧数据不完整。
- 重试策略冲突：`MqttPublishingService` 通常会用 Polly 做熔断 / 重试，但连续事件的重试是独立的：
  - 比如对 `DataPersistEvent` 配置了重试，而 `ThingModelParsedEvent` 未配置，可能出现 “解析事件失败、存储事件重试成功” 的异常状态；
  - ABP 事件总线自身的重试（若配置）与 Polly 重试叠加，会导致事件被重复消费（比如重复解析、重复存储），产生脏数据。

#### 4. 可维护性 / 调试层面：流程黑盒 + 问题定位成本极高（最不优雅的工程实践）

- 流程不可见：连续发布事件让 MQTT 消息的处理流程从 “线性代码” 变成 “事件黑盒”—— 要查 “一条消息为什么没存储”，需要遍历：`MqttPublishingService `事件发布日志 → 事件总线传输日志 → 事件处理器执行日志，全链路日志分散，调试效率极低；
- **事件粒度失控**：连续发布易导致事件粒度混乱（比如既有 “原始数据接收” 粗粒度事件，又有 “温度字段解析” 细粒度事件），事件名称、数据结构缺乏统一规范，后续新增 / 删除事件会引发 “事件爆炸”，代码可读性极差。

#### 5. 违背 ABP 事件总线的设计原则（底层逻辑不优雅）

ABP 官方明确：**事件是 “状态变更的通知”，而非 “业务指令的传递”**。但连续发布事件的做法，本质是把 “解析数据”、“存储数据” 等「命令式操作」包装成事件，违背设计初衷：

- 比如发布 `ThingModelParsedEvent` 不是 “通知下游‘数据已解析’”，而是 “命令下游‘去解析这条数据’”；
- 若解析、存储等逻辑在同一个微服务内，完全没必要用分布式事件，直接调用方法更高效，属于 “过度设计”。

### 二、典型反例（代码层面的不优雅）

```csharp
// MqttPublishingService 中连续发布事件的反例
public async Task HandleMqttMessageAsync(MqttApplicationMessage message)
{
    // 1. 发布原始数据接收事件
    await _distributedEventBus.PublishAsync(new RawDataReceivedEvent(message));
    
    // 2. 解析后发布物模型事件
    var parsedData = _parser.Parse(message);
    await _distributedEventBus.PublishAsync(new ThingModelParsedEvent(parsedData));
    
    // 3. 发布存储事件
    await _distributedEventBus.PublishAsync(new DataPersistEvent(parsedData));
    
    // 问题：无异常隔离、无顺序保障、无资源管控
}
```

这段代码的核心问题：

- 单个事件发布失败会导致后续全中断，无兜底逻辑；
- 事件总线异步特性可能导致下游处理器 “先收到存储事件，后收到解析事件”；
- 高并发下无限流，直接打满事件总线连接池。

### 三、优化方向（解决 “连续套用事件总线” 的不优雅）

#### 1. 重构事件粒度与职责边界

- **合并冗余事件**：将 “接收→解析→存储” 的连续事件合并为一个「业务域事件」（如 `MqttDeviceDataReportedEvent`），仅发布一次事件，下游处理器按需拆分逻辑；
- **区分本地 / 分布式事件**：同微服务内的解析、存储用「本地方法调用」，跨微服务的通知（如给告警服务发通知）用「分布式事件」，避免过度使用分布式事件。

#### 2. 引入 “事务性发件箱（Outbox）” 保障一致性

基于 ABP 的「事务性发件箱模式」（ABP 内置支持），将事件发布纳入 UnitOfWork 事务：

```csharp
[UnitOfWork]
public async Task HandleMqttMessageAsync(MqttApplicationMessage message)
{
    // 1. 业务处理（解析等）
    var parsedData = _parser.Parse(message);
    
    // 2. 事件加入发件箱（UOW 提交后才批量发布）
    await _distributedEventBus.PublishAsync(new MqttDeviceDataReportedEvent(parsedData));
    
    // UOW 提交：保障“解析成功→事件发布成功”的原子性
    await CurrentUnitOfWork.SaveChangesAsync();
}
```

#### 3. 批量事件发布优化

对同一类型的事件做 “攒批发布”，而非单条连续发布：

```csharp
// 批量攒批 MQTT 消息
private readonly List<MqttDeviceDataReportedEvent> _eventBatch = new();
private readonly PeriodicTimer _timer = new(TimeSpan.FromMilliseconds(100));

public async Task AddToBatchAsync(MqttApplicationMessage message)
{
    var parsedData = _parser.Parse(message);
    _eventBatch.Add(new MqttDeviceDataReportedEvent(parsedData));
    
    // 达到阈值或超时则批量发布
    if (_eventBatch.Count >= 100 || await _timer.WaitForNextTickAsync())
    {
        await _distributedEventBus.PublishManyAsync(_eventBatch);
        _eventBatch.Clear();
    }
}
```

#### 4. 引入流程编排（显性化事件依赖）

用状态机（如 Stateless）或工作流引擎（ABP Workflow）管控事件触发顺序，替代 “连续 Publish” 的隐式依赖：

```csharp
// 用状态机显性化流程
var machine = new StateMachine<DataState, DataTrigger>(DataState.Received);
machine.Configure(DataState.Received)
    .Permit(DataTrigger.Parse, DataState.Parsed);
machine.Configure(DataState.Parsed)
    .Permit(DataTrigger.Persist, DataState.Persisted);

// 触发状态变更时发布事件
machine.Fire(DataTrigger.Parse);
await _eventBus.PublishAsync(new ThingModelParsedEvent(parsedData));
```

#### 5. 精简 MqttPublishingService 职责

让 MqttPublishingService 仅负责 “MQTT 消息接收 + 基础校验”，发布一个「原始数据可用事件」后不再干预后续流程，下游模块（解析、存储）自行订阅该事件并处理，彻底解耦：

```csharp
// 优化后：仅发布一个核心事件
public async Task HandleMqttMessageAsync(MqttApplicationMessage message)
{
    // 仅做基础校验（如设备合法性、消息格式）
    if (!_deviceValidator.Validate(message)) return;
    
    // 发布单次事件，下游自行处理解析、存储等逻辑
    await _distributedEventBus.PublishAsync(new MqttRawDataAvailableEvent(message));
}
```

### 总结

MqttPublishingService 中 “连续套用 ABP 事件总线” 的核心问题是：**把事件总线从 “解耦工具” 变成了 “流程管控工具”**，既放大了事件总线的性能开销，又丧失了其解耦的初衷，同时引入了数据一致性和可维护性的风险。

优化的核心思路是：**回归事件总线的 “通知本质”，精简事件数量、区分本地 / 分布式事件、显性化流程依赖**，让 MqttPublishingService 聚焦 MQTT 协议层职责，而非事件调度。



## 附:代码

**MqttPublishingService.cs** 代码清单：

```C#
using Artizan.IoT.Mqtts.Etos;
using Artizan.IoT.Mqtts.Signs;
using Artizan.IoTHub.Localization;
using Artizan.IoTHub.Mqtts.Options;
using Artizan.IoTHub.Mqtts.Options.Pollys;
using Microsoft.Extensions.Localization;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;
using MQTTnet.Server;
using Polly;
using Polly.Bulkhead;
using Polly.CircuitBreaker;
using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Volo.Abp.DependencyInjection;
using Volo.Abp.EventBus.Distributed;
using Volo.Abp.Guids;

namespace Artizan.IoTHub.Mqtts.Servers;

/// <summary>
/// MQTT消息发布服务（生产环境核心服务）
/// 【设计定位】：作为MQTT服务器与分布式事件总线的中间层，核心职责是接收MQTT设备消息并发布到事件总线
/// 【核心能力】：
/// 1. 消息接收与校验：过滤无效消息，提取设备认证信息
/// 2. 容错保护：基于Polly实现熔断+隔离策略，防止事件总线故障扩散
/// 3. 性能优化：批量发布减少事件总线调用开销，支持高并发（每秒1万+数据点）
/// 4. 降级重试：本地队列缓存失败消息，后台自动重试保证消息不丢失
/// 5. 动态配置：支持配置热更新，无需重启服务即可调整策略参数
/// 6. 高并发场景：对于高并发场景，启用批量发布的性能优势，消息达到数量阈值时立即发布消息
/// 7. 消息频率低场景：对于设备数量少、消息频率低的场景，即使消息数量没达到阈值，只要超过设定的超时时间，也会触发消息发布。
/// </summary>
[ExposeServices(typeof(IMqttPublishingService), typeof(IMqttService))] // ABP依赖注入：暴露服务接口
public class MqttPublishingService : MqttServiceBase, IMqttPublishingService, ISingletonDependency, IDisposable
{
    #region 核心成员变量（设计思路：分层管理，职责单一）
    // ---------------------Polly 策略层---------------------
    // 熔断器策略：保护事件总线发布操作，故障时快速失败避免雪崩
    private AsyncCircuitBreakerPolicy _eventBusCircuitBreaker;
    // 隔离策略：限制并发处理量，保护MQTT服务器主线程不被压垮
    private AsyncBulkheadPolicy _bulkheadPolicy;
    // 策略更新锁：保证多线程下策略更新的原子性（防止读写冲突）
    private readonly object _policyLock = new object();

    //---------------------降级重试层---------------------
    // 本地降级队列：事件总线不可用时临时存储消息（内存级兜底，保证不丢失）
    // 选型原因：ConcurrentQueue是线程安全队列，无锁设计，高并发下性能优于Queue+lock
    private ConcurrentQueue<MqttClientPublishTopicEto> _fallbackQueue;
    // 后台重试任务锁：控制重试循环的并发执行（防止重复消费队列）
    // 选型原因：SemaphoreSlim轻量级锁，支持异步等待，适合后台任务
    private SemaphoreSlim _retryLock = new SemaphoreSlim(1, 1);

    //---------------------批量发布层---------------------
    // 按主题分组的批量发布队列：避免不同主题消息混批，保证业务隔离
    private ConcurrentDictionary<string, ConcurrentQueue<MqttClientPublishTopicEto>> _batchPublishQueue;
    // 批量发布取消令牌：优雅停止批量发布循环（支持配置动态关闭优化）
    private CancellationTokenSource _batchPublishCts;
    // 批量处理锁：防止多线程并发处理同一主题队列（避免消息重复发布）
    private readonly SemaphoreSlim _batchProcessLock = new SemaphoreSlim(1, 1);
    //+ 记录每个主题的最后消息加入时间：用于实现超时自动发布
    private ConcurrentDictionary<string, DateTime> _topicLastEnqueueTime;

    //---------------------配置层---------------------
    // 当前生效的MQTT配置：缓存验证后的配置，避免每次读取配置都校验
    protected IoTMqttOptions CurrentIoTMqttOptions { get; private set; }

    //---------------------基础依赖层---------------------
    protected ILogger<MqttPublishingService> Logger { get; } // 日志：生产环境必备，便于问题排查
    protected IGuidGenerator GuidGenerator { get; } // GUID生成：为每条消息生成唯一追踪ID
    protected IDistributedEventBus DistributedEventBus { get; } // 分布式事件总线：核心发布目标
    protected IStringLocalizer<IoTHubResource> Localizer { get; } // 本地化：支持多语言日志（可选）
    // 配置监控：支持配置热更新，配置变更时自动触发回调
    private readonly IOptionsMonitor<IoTMqttOptions> _ioTMqttOptionsMonitor;
    #endregion

    /// <summary>
    /// 构造函数（依赖注入+初始化核心资源）
    /// 【设计思路】：
    /// 1. 依赖通过构造函数注入，符合DI原则，便于单元测试
    /// 2. 初始化配置时带默认值兜底，防止配置缺失导致服务启动失败
    /// 3. 提前初始化核心组件（队列、策略），避免运行时首次调用的性能损耗
    /// </summary>
    public MqttPublishingService(
        ILogger<MqttPublishingService> logger,
        IGuidGenerator guidGenerator,
        IDistributedEventBus distributedEventBus,
        IStringLocalizer<IoTHubResource> localizer,
        IOptionsMonitor<IoTMqttOptions> ioTMqttOptionsMonitor)
       : base()
    {
        // 基础依赖赋值
        Logger = logger;
        GuidGenerator = guidGenerator;
        DistributedEventBus = distributedEventBus;
        Localizer = localizer;
        _ioTMqttOptionsMonitor = ioTMqttOptionsMonitor;

        // 初始化配置（核心设计：配置验证+默认值兜底）
        // 原因：生产环境配置可能缺失或非法，提前验证可避免运行时异常
        CurrentIoTMqttOptions = GetValidatedOptions(_ioTMqttOptionsMonitor.CurrentValue) ?? new IoTMqttOptions
        {
            // Polly默认配置：基于经验值，适配大多数场景
            Polly = new PollyOptions
            {
                CircuitBreaker = new CircuitBreakerOptions { ExceptionsAllowedBeforeBreaking = 10, DurationOfBreakSeconds = 30 },
                Bulkhead = new BulkheadOptions { MaxParallelization = 10000, MaxQueuingActions = 1000 },
                Retry = new RetryOptions { RetryIntervalSeconds = 5, MaxRetryPerLoop = 100 }
            },
            // 批量优化默认配置：默认关闭，避免影响现有逻辑
            PublishingOptimization = new PublishingOptimizationOptions
            {
                EnableOptimizations = false,
                BatchPublishThreshold = 100,
                BatchPublishIntervalMs = 100,
                // 新增：单条消息超时发布时间（毫秒）
                SingleMessagePublishTimeoutMs = 300,
                TopicBasedThrottling = new Dictionary<string, int>()
            }
        };

        // 初始化降级队列（提前创建，避免首次使用时的初始化开销）
        _fallbackQueue = new ConcurrentQueue<MqttClientPublishTopicEto>();

        // 初始化Polly策略（启动时创建，避免运行时动态创建的性能损耗）
        _eventBusCircuitBreaker = InitCircuitBreakerPolicy();
        _bulkheadPolicy = InitBulkheadPolicy();

        // 监听配置变更（核心设计：配置热更新）
        // 原因：生产环境调整配置无需重启服务，提升可用性
        _ioTMqttOptionsMonitor.OnChange(OnIoTMqttOptionsChanged);

        // 启动后台重试任务（火并忘记模式：_ = 不等待，后台持续运行）
        // 原因：重试任务是后台常驻任务，无需阻塞服务启动
        _ = StartFallbackRetryLoopAsync();

        // 初始化批量发布队列（按需创建，未启用优化时不占用内存）
        if (CurrentIoTMqttOptions.PublishingOptimization.EnableOptimizations)
        {
            _batchPublishQueue = new ConcurrentDictionary<string, ConcurrentQueue<MqttClientPublishTopicEto>>();

            //初始化主题最后入队时间字典
            _topicLastEnqueueTime = new ConcurrentDictionary<string, DateTime>();

            _ = StartBatchPublishLoopAsync();
            Logger.LogInformation("MQTT发布拦截器[{Name}] | 批量发布优化已启用 | 阈值：{0}条 | 间隔：{1}ms | 单条超时：{2}ms",
                nameof(MqttPublishingService),
                CurrentIoTMqttOptions.PublishingOptimization.BatchPublishThreshold,
                CurrentIoTMqttOptions.PublishingOptimization.BatchPublishIntervalMs,
                CurrentIoTMqttOptions.PublishingOptimization.SingleMessagePublishTimeoutMs);
        }

        Logger.LogInformation("MQTT发布拦截器[{Name}] | Polly配置：熔断失败次数={0} | 隔离最大并发={1}",
            nameof(MqttPublishingService),
            CurrentIoTMqttOptions.Polly.CircuitBreaker.ExceptionsAllowedBeforeBreaking,
            CurrentIoTMqttOptions.Polly.Bulkhead.MaxParallelization);
    }

    /// <summary>
    /// 配置MQTT服务器（注册发布拦截器）
    /// 【设计思路】：
    /// 1. 重写基类方法，符合开闭原则
    /// 2. 注册InterceptingPublishAsync事件，拦截所有MQTT发布消息
    /// 3. 拦截器是MQTTnet的核心扩展点，可在消息发布前做自定义处理
    /// </summary>
    public override void ConfigureMqttServer(MqttServer mqttServer)
    {
        base.ConfigureMqttServer(mqttServer);
        // 注册发布拦截器：所有设备发布的消息都会经过此回调处理
        MqttServer.InterceptingPublishAsync += InterceptingPublishHandlerAsync;
        Logger.LogInformation("MQTT发布拦截器[{Name}] | 已注册 | 服务就绪", nameof(MqttPublishingService));
    }

    #region 配置管理（核心设计：验证+热更新）
    /// <summary>
    /// IoT MQTT配置变更处理（配置热更新核心方法）
    /// 【设计思路】：
    /// 1. 配置变更时先验证，无效则使用现有配置，避免服务异常
    /// 2. 加锁更新配置和策略，保证线程安全
    /// 3. 动态调整批量发布开关，无需重启服务
    /// </summary>
    /// <param name="newOptions">新的配置值（从配置文件/配置中心获取）</param>
    private void OnIoTMqttOptionsChanged(IoTMqttOptions newOptions)
    {
        try
        {
            Logger.LogInformation("MQTT发布拦截器[{Name}] | 收到配置变更通知 | 新配置：{1}",
                nameof(MqttPublishingService),
                Newtonsoft.Json.JsonConvert.SerializeObject(newOptions));

            // 第一步：验证新配置（核心：过滤非法配置，保证服务稳定性）
            var validatedOptions = GetValidatedOptions(newOptions);
            if (validatedOptions == null)
            {
                Logger.LogWarning("MQTT发布拦截器[{Name}] | 配置验证失败 | 使用现有配置", nameof(MqttPublishingService));
                return;
            }

            // 第二步：加锁更新配置和策略（线程安全）
            // 原因：多线程下可能同时更新配置，lock保证原子性
            lock (_policyLock)
            {
                // 更新缓存的配置
                CurrentIoTMqttOptions = validatedOptions;

                // 重新初始化Polly策略（配置变更后策略需同步更新）
                _eventBusCircuitBreaker = InitCircuitBreakerPolicy();
                _bulkheadPolicy = InitBulkheadPolicy();
                Logger.LogInformation("Polly策略已更新 | 新熔断失败次数={0} | 新隔离最大并发={1}",
                    CurrentIoTMqttOptions.Polly.CircuitBreaker.ExceptionsAllowedBeforeBreaking,
                    CurrentIoTMqttOptions.Polly.Bulkhead.MaxParallelization);

                // 第三步：处理批量发布配置变更
                var wasEnabled = CurrentIoTMqttOptions.PublishingOptimization.EnableOptimizations;
                var newEnabled = validatedOptions.PublishingOptimization.EnableOptimizations;

                if (newEnabled && !wasEnabled)
                {
                    // 启用批量发布：初始化队列并启动循环
                    _batchPublishQueue = new ConcurrentDictionary<string, ConcurrentQueue<MqttClientPublishTopicEto>>();
                    // 初始化主题最后入队时间字典
                    _topicLastEnqueueTime = new ConcurrentDictionary<string, DateTime>();

                    _ = StartBatchPublishLoopAsync();

                    Logger.LogInformation("MQTT发布拦截器[{Name}] | 批量发布优化已启用 | 阈值：{1}条 | 间隔：{2}ms | 单条超时：{3}ms",
                         nameof(MqttPublishingService),
                         validatedOptions.PublishingOptimization.BatchPublishThreshold,
                         validatedOptions.PublishingOptimization.BatchPublishIntervalMs,
                         validatedOptions.PublishingOptimization.SingleMessagePublishTimeoutMs);
                }
                else if (!newEnabled && wasEnabled)
                {
                    // 禁用批量发布：取消循环并清空队列
                    _batchPublishCts?.Cancel();
                    _batchPublishQueue = null;

                    //+ 清理时间记录字典
                    _topicLastEnqueueTime = null;

                    Logger.LogInformation("MQTT发布拦截器[{Name}] | 批量发布优化已禁用", nameof(MqttPublishingService));
                }
                else if (newEnabled && wasEnabled)  // 配置变更但开关状态不变时也记录批量参数
                {
                    Logger.LogInformation("MQTT发布拦截器[{Name}] | 批量发布配置已更新 | 新阈值：{1}条 | 新间隔：{2}ms | 单条超时：{3}ms",
                        nameof(MqttPublishingService),
                        validatedOptions.PublishingOptimization.BatchPublishThreshold,
                        validatedOptions.PublishingOptimization.BatchPublishIntervalMs,
                        validatedOptions.PublishingOptimization.SingleMessagePublishTimeoutMs);
                }
            }
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "处理配置变更失败 | 服务将继续使用现有配置");
        }
    }

    /// <summary>
    /// 验证配置并返回有效配置（核心设计：默认值兜底+非法值过滤）
    /// 【设计原因】：
    /// 1. 配置文件可能缺失字段，默认值保证服务能启动
    /// 2. 配置值可能为负数/零，过滤后避免运行时异常（如熔断次数为0会立即熔断）
    /// 3. 限流配置可能有无效主题，提前清理减少运行时判断
    /// </summary>
    /// <param name="options">待验证的配置</param>
    /// <returns>验证后的有效配置（null表示验证失败）</returns>
    private IoTMqttOptions GetValidatedOptions(IoTMqttOptions options)
    {
        if (options == null) return null;

        try
        {
            // 1. 验证Polly配置（核心容错策略，必须保证有效）
            var pollyOptions = options.Polly ?? new PollyOptions();
            pollyOptions.CircuitBreaker = pollyOptions.CircuitBreaker ?? new CircuitBreakerOptions();
            pollyOptions.Bulkhead = pollyOptions.Bulkhead ?? new BulkheadOptions();
            pollyOptions.Retry = pollyOptions.Retry ?? new RetryOptions();

            // 填充Polly默认值（过滤非法值）
            pollyOptions.CircuitBreaker.ExceptionsAllowedBeforeBreaking = pollyOptions.CircuitBreaker.ExceptionsAllowedBeforeBreaking <= 0
                ? 10 : pollyOptions.CircuitBreaker.ExceptionsAllowedBeforeBreaking; // 熔断失败次数不能≤0
            pollyOptions.CircuitBreaker.DurationOfBreakSeconds = pollyOptions.CircuitBreaker.DurationOfBreakSeconds <= 0
                ? 30 : pollyOptions.CircuitBreaker.DurationOfBreakSeconds; // 熔断时长不能≤0
            pollyOptions.Bulkhead.MaxParallelization = pollyOptions.Bulkhead.MaxParallelization <= 0
                ? 10000 : pollyOptions.Bulkhead.MaxParallelization; // 最大并发不能≤0
            pollyOptions.Bulkhead.MaxQueuingActions = pollyOptions.Bulkhead.MaxQueuingActions < 0
                ? 1000 : pollyOptions.Bulkhead.MaxQueuingActions; // 最大队列不能<0
            pollyOptions.Retry.RetryIntervalSeconds = pollyOptions.Retry.RetryIntervalSeconds <= 0
                ? 5 : pollyOptions.Retry.RetryIntervalSeconds; // 重试间隔不能≤0
            pollyOptions.Retry.MaxRetryPerLoop = pollyOptions.Retry.MaxRetryPerLoop <= 0
                ? 100 : pollyOptions.Retry.MaxRetryPerLoop; // 重试次数不能≤0

            // 2. 验证发布优化配置
            var optimizationOptions = options.PublishingOptimization ?? new PublishingOptimizationOptions();
            optimizationOptions.BatchPublishThreshold = optimizationOptions.BatchPublishThreshold > 0
                ? optimizationOptions.BatchPublishThreshold : 100; // 批量阈值必须>0
            optimizationOptions.BatchPublishIntervalMs = optimizationOptions.BatchPublishIntervalMs > 0
                ? optimizationOptions.BatchPublishIntervalMs : 100; // 检查间隔必须>0

            // 验证单条消息超时配置,单设备单条消息：等待 x 秒后自动发布（即时通讯），平衡即时性和批量性能
            optimizationOptions.SingleMessagePublishTimeoutMs = optimizationOptions.SingleMessagePublishTimeoutMs > 0
                ? optimizationOptions.SingleMessagePublishTimeoutMs : 300; // 单条超时必须>0

            optimizationOptions.TopicBasedThrottling = optimizationOptions.TopicBasedThrottling ?? new Dictionary<string, int>();

            // 清理无效的限流配置（空主题/负数限流值）
            optimizationOptions.TopicBasedThrottling = optimizationOptions.TopicBasedThrottling
                .Where(kv => !string.IsNullOrWhiteSpace(kv.Key) && kv.Value > 0)
                .ToDictionary(kv => kv.Key, kv => kv.Value);

            // 返回验证后的配置
            return new IoTMqttOptions
            {
                Polly = pollyOptions,
                PublishingOptimization = optimizationOptions
            };
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "配置验证失败");
            return null;
        }
    }
    #endregion

    #region Polly策略设计（核心容错机制）
    /// <summary>
    /// 初始化熔断策略（Circuit Breaker）
    /// 【设计思路】：
    /// 1. 熔断策略：失败次数达到阈值后，快速失败一段时间，避免无效请求浪费资源
    /// 2. 适用场景：事件总线暂时不可用（如网络故障、MQ集群宕机）
    /// 3. 核心参数：失败次数+熔断时长，可通过配置动态调整
    /// 4. 异常过滤：忽略取消/超时异常，避免瞬时异常触发熔断
    /// </summary>
    /// <returns>异步熔断策略</returns>
    private AsyncCircuitBreakerPolicy InitCircuitBreakerPolicy()
    {
        var config = CurrentIoTMqttOptions.Polly.CircuitBreaker;

        return Policy
            // 异常过滤：仅处理非取消/非超时异常（瞬时异常不触发熔断）
            .Handle<Exception>(ex => ex is not OperationCanceledException and not TimeoutException)
            .CircuitBreakerAsync(
                exceptionsAllowedBeforeBreaking: config.ExceptionsAllowedBeforeBreaking, // 熔断前允许的失败次数
                durationOfBreak: TimeSpan.FromSeconds(config.DurationOfBreakSeconds), // 熔断持续时间
                // 熔断开启回调：记录日志，便于监控告警                                                  
                onBreak: (exception, breakDuration) =>    
                {
                    Logger.LogWarning(
                        "MQTT发布拦截器[{Name}] | [熔断策略] 开启 | 失败次数={0} | 持续时间={1}s | 原因={2}",
                        nameof(MqttPublishingService),
                        config.ExceptionsAllowedBeforeBreaking, breakDuration.TotalSeconds, exception?.Message ?? "未知异常"
                    );
                },
                // 熔断重置回调：恢复正常，记录日志
                onReset: () => Logger.LogInformation("MQTT发布拦截器[{Name}] | [熔断策略] 重置 | 恢复正常处理", nameof(MqttPublishingService)),
                // 熔断半开回调：尝试恢复，记录日志
                onHalfOpen: () => Logger.LogInformation("MQTT发布拦截器[{Name}] | [熔断策略] 半开 | 尝试处理请求验证恢复", nameof(MqttPublishingService))
            );
    }

    /// <summary>
    /// 初始化隔离策略（Bulkhead）
    /// 【设计思路】：
    /// 1. 隔离策略：限制并发执行数和排队数，防止单个组件故障拖垮整个服务
    /// 2. 适用场景：事件总线处理慢，请求堆积导致MQTT服务器线程耗尽
    /// 3. 核心参数：最大并发数+最大排队数，可通过配置动态调整
    /// 4. 限流回调：限流时将消息加入降级队列，保证不丢失
    /// </summary>
    /// <returns>异步隔离策略</returns>
    private AsyncBulkheadPolicy InitBulkheadPolicy()
    {
        var config = CurrentIoTMqttOptions.Polly.Bulkhead;

        return Policy
            .BulkheadAsync(
                maxParallelization: config.MaxParallelization, // 最大并发执行数（控制同时发布的请求数）
                maxQueuingActions: config.MaxQueuingActions, // 最大排队数（超出则触发限流）
                // 限流回调：将消息加入降级队列，保证不丢失
                onBulkheadRejectedAsync: async (context) =>
                {
                    Logger.LogWarning(
                        "MQTT发布拦截器[{Name}] | [隔离策略] 限流触发 | 最大并发={0} | 最大队列={1}",
                        nameof(MqttPublishingService),
                        config.MaxParallelization, config.MaxQueuingActions
                    );

                    // 从上下文获取消息对象，加入降级队列
                    if (context["Eto"] is MqttClientPublishTopicEto eto)
                    {
                        _fallbackQueue.Enqueue(eto);
                        Logger.LogWarning("[TrackId:{TrackId}] 因隔离策略限流 | 加入重试队列", eto.MqttTrackId);
                    }
                    await Task.CompletedTask;
                }
            );
    }

    /// <summary>
    /// 组合策略（先隔离后熔断）
    /// 【设计思路】：
    /// 1. 策略组合顺序：先隔离（控制并发），后熔断（快速失败）
    /// 2. 双重检查锁定：保证多线程下获取的是最新策略，且无性能损耗
    /// 3. 适用场景：高并发下先限制并发，再防止故障扩散
    /// </summary>
    /// <returns>组合后的异步策略</returns>
    private IAsyncPolicy GetCombinedPolicy()
    {
        // 双重检查锁定：第一次检查无锁，第二次加锁，平衡性能和线程安全
        lock (_policyLock)
        {
            // 策略组合：隔离策略在外层，熔断策略在内层
            // 原因：先限制并发，再判断是否熔断，符合容错优先级
            return Policy.WrapAsync(_bulkheadPolicy, _eventBusCircuitBreaker);
        }
    }
    #endregion

    #region 降级重试设计（保证消息不丢失）
    /// <summary>
    /// 后台重试队列处理循环（常驻后台任务）
    /// 【设计思路】：
    /// 1. 无限循环：持续监听降级队列，保证消息最终能被处理
    /// 2. 延迟重试：按配置的间隔重试，避免频繁重试加剧事件总线压力
    /// 3. 熔断判断：熔断开启时跳过重试，避免无效请求
    /// 4. 批量重试：每次重试最多处理配置的数量，防止单次重试过多
    /// 5. 异常保护：捕获所有异常，保证重试线程不崩溃
    /// </summary>
    /// <returns>异步任务</returns>
    private async Task StartFallbackRetryLoopAsync()
    {
        // 无限循环：后台常驻，直到服务停止
        while (true)
        {
            try
            {
                // 延迟重试：使用配置的重试间隔，减少无效轮询
                await Task.Delay(TimeSpan.FromSeconds(CurrentIoTMqttOptions.Polly.Retry.RetryIntervalSeconds))
                    .ConfigureAwait(false); // 非上下文切换，提升性能

                // 熔断开启或队列为空时跳过（核心：避免无效重试）
                if (_fallbackQueue.IsEmpty || _eventBusCircuitBreaker.CircuitState == CircuitState.Open)
                {
                    continue;
                }

                // 加锁：防止多线程并发重试，导致消息重复处理
                await _retryLock.WaitAsync().ConfigureAwait(false);

                int retrySuccessCount = 0;
                // 批量重试：每次最多处理MaxRetryPerLoop条，防止单次处理过多
                for (int i = 0; i < CurrentIoTMqttOptions.Polly.Retry.MaxRetryPerLoop && _fallbackQueue.TryDequeue(out var eto); i++)
                {
                    try
                    {
                        // 发布消息到事件总线（使用OuseOutbox: true保证可靠性, onUnitOfWorkComplete: false 不等待事务，该场景下适用）
                        await DistributedEventBus.PublishAsync(eto, onUnitOfWorkComplete: false, useOutbox: true)
                            .ConfigureAwait(false);

                        retrySuccessCount++;
                        Logger.LogInformation("[TrackId:{TrackId}] 重试发布成功", eto.MqttTrackId);
                    }
                    catch (Exception ex)
                    {
                        // 重试失败：将消息重新加入队列，等待下次重试
                        _fallbackQueue.Enqueue(eto);
                        Logger.LogWarning("[TrackId:{TrackId}] 重试发布失败 | 原因={0}", eto.MqttTrackId, ex.Message);
                        break; // 遇到错误暂停重试，避免雪崩
                    }
                }

                // 日志：重试统计，便于监控
                if (retrySuccessCount > 0)
                {
                    Logger.LogInformation("[重试任务] 成功={0}条 | 剩余队列={1}条", retrySuccessCount, _fallbackQueue.Count);
                }
            }
            catch (Exception ex)
            {
                // 捕获所有异常：保证重试线程不崩溃
                Logger.LogError(ex, "[重试任务] 线程异常 | 已自动恢复");
            }
            finally
            {
                // 释放锁：必须在finally中释放，防止死锁
                _retryLock.Release();
            }
        }
    }
    #endregion

    #region 批量发布设计（高并发性能优化 + 超时发布）
    /// <summary>
    /// 批量发布处理循环（定时检查+阈值触发+超时触发）
    /// 【设计思路】：
    /// 1. 定时检查：按配置的间隔检查队列，保证消息延迟可控
    /// 2. 阈值触发：达到批量阈值立即处理，减少消息延迟
    /// 3. 超时触发：超过最大等待时间即使未达阈值也处理，保证即时性
    /// 4. 按主题分组：不同主题消息分开批量，保证业务隔离
    /// 5. 优雅停止：支持取消令牌，配置关闭时优雅停止循环
    /// 6. 并发控制：加锁防止多线程处理同一队列，避免重复发布
    /// </summary>
    /// <returns>异步任务</returns>
    private async Task StartBatchPublishLoopAsync()
    {
        // 创建取消令牌：用于优雅停止批量循环
        _batchPublishCts = new CancellationTokenSource();
        var cancellationToken = _batchPublishCts.Token;

        try
        {
            // 无限循环：持续检查批量队列
            while (!cancellationToken.IsCancellationRequested)
            {
                // 每次当前配置的间隔时间等待（每次循环重新获取最新配置）
                var interval = CurrentIoTMqttOptions.PublishingOptimization.BatchPublishIntervalMs;
                await Task.Delay(interval, cancellationToken).ConfigureAwait(false);

                // 未启用优化或队列为空时跳过
                if (!CurrentIoTMqttOptions.PublishingOptimization.EnableOptimizations || _batchPublishQueue == null)
                {
                    continue;
                }

                // 加锁：防止多线程并发处理同一主题队列
                await _batchProcessLock.WaitAsync(cancellationToken).ConfigureAwait(false);

                try
                {
                    // 遍历所有主题队列，处理达到阈值或超时的队列
                    foreach (var topic in _batchPublishQueue.Keys.ToList()) // ToList：防止遍历中集合变更
                    {
                        if (_batchPublishQueue.TryGetValue(topic, out var topicQueue) && topicQueue.Count > 0)
                        {
                            // 检查是否达到阈值或超时
                            bool thresholdReached = topicQueue.Count >= CurrentIoTMqttOptions.PublishingOptimization.BatchPublishThreshold;
                            // 超时判断初始化
                            bool timeoutReached = false;

                            if (_topicLastEnqueueTime.TryGetValue(topic, out var lastTime))
                            {
                                // 核心：计算当前时间与最后入队时间的差值，判断是否超过超时配置
                                timeoutReached = DateTime.UtcNow - lastTime >= TimeSpan.FromMilliseconds(CurrentIoTMqttOptions.PublishingOptimization.SingleMessagePublishTimeoutMs);
                            }

                            // 满足「数量阈值」或「超时」任一条件即发布
                            if (thresholdReached || timeoutReached)
                            {
                                // 调用原有单参数重载，保持兼容性
                                await ProcessBatchQueueAsync(topicQueue).ConfigureAwait(false);
                                // 处理完成后移除时间记录
                                _topicLastEnqueueTime.TryRemove(topic, out _);
                            }
                        }
                    }
                }
                finally
                {
                    // 释放锁：必须在finally中释放
                    _batchProcessLock.Release();
                }
            }
        }
        catch (OperationCanceledException)
        {
            // 取消异常：正常停止，记录日志
            Logger.LogInformation("[批量发布] 循环已取消 | 优化功能已禁用");
        }
        catch (Exception ex)
        {
            // 捕获所有异常：保证批量线程不崩溃
            Logger.LogError(ex, "[批量发布] 循环异常 | 已自动恢复");
        }
    }

    /// <summary>
    /// 处理单个主题的批量发布队列
    /// 【设计思路】：
    /// 1. 批量取出：一次性取出队列中所有消息，减少队列操作次数
    /// 2. 并行发布：使用Task.WhenAll并行发布，减少事件总线调用开销
    /// 3. 策略保护：使用组合策略（隔离+熔断）保护批量发布
    /// 4. 失败回退：发布失败时将消息退回队列，保证不丢失
    /// </summary>
    /// <param name="queue">单个主题的消息队列</param>
    /// <returns>异步任务</returns>
    private async Task ProcessBatchQueueAsync(ConcurrentQueue<MqttClientPublishTopicEto> queue)
    {
        // 批量取出队列中的所有消息（原子操作，减少队列锁竞争）
        var batch = new List<MqttClientPublishTopicEto>();
        while (queue.TryDequeue(out var eto))
        {
            batch.Add(eto);
        }

        // 空批次直接返回
        if (batch.Count == 0)
            return;

        try
        {
            Logger.LogDebug("[批量发布] | [处理消息] -> [事件总线] | 主题={0} | 数量={1}条", batch.First().MqttTopic, batch.Count);

            // 使用组合策略保护批量发布（隔离+熔断）
            await GetCombinedPolicy().ExecuteAsync(async () =>
            {
                // 核心优化：批量并行发布
                var publishTasks = batch.Select(eto =>
                    DistributedEventBus.PublishAsync(eto, onUnitOfWorkComplete: false, useOutbox: true)
                );

                // 并行等待所有发布任务完成，减少上下文切换
                await Task.WhenAll(publishTasks).ConfigureAwait(false);
            }).ConfigureAwait(false);

            Logger.LogDebug("[批量发布] | [处理成功] -> [事件总线] | 主题={0} | 数量={1}条", batch.First().MqttTopic, batch.Count);
        }
        catch (Exception ex)
        {
            // 发布失败：将消息退回队列，保证不丢失
            Logger.LogError(ex, "[批量发布] | [处理失败] X-> [事件总线]  | 主题={0} | 数量={1}条 | 消息已退回队列",
                batch.First().MqttTopic, batch.Count);
            foreach (var eto in batch)
            {
                queue.Enqueue(eto);
            }
            // 恢复时间记录以便重新计时
            _topicLastEnqueueTime[batch.First().MqttTopic] = DateTime.UtcNow;
        }
    }

    /// <summary>
    ///  消息入队时更新时间戳（新增辅助方法，不修改原有入队逻辑）
    /// </summary>
    /// <param name="topic"></param>

    private void UpdateTopicEnqueueTime(string topic)
    {
        if (_topicLastEnqueueTime != null)
        {
            _topicLastEnqueueTime[topic] = DateTime.UtcNow;
        }
    }
    #endregion

    #region 核心消息处理（MQTT消息拦截+发布）
    /// <summary>
    /// MQTT发布消息拦截处理（核心业务逻辑，仅新增时间戳更新）
    /// 【设计思路】：
    /// 1. 快速失败：先做基础校验，无效消息直接拒绝，减少资源消耗
    /// 2. 分级校验：设备认证→设备信息→消息内容，逐步深入
    /// 3. 性能优化：内存零拷贝（AsSpan）、分级日志（Debug级别才输出详细信息）
    /// 4. 分支处理：启用批量则走批量队列，否则走单条发布
    /// 5. 异常保护：捕获所有异常，保证拦截器不崩溃，不影响其他消息
    /// </summary>
    /// <param name="eventArgs">MQTT发布事件参数</param>
    /// <returns>异步任务</returns>
    private async Task InterceptingPublishHandlerAsync(InterceptingPublishEventArgs eventArgs)
    {
        // 生成唯一追踪ID：便于全链路日志追踪
        var trackId = GuidGenerator.Create().ToString();
        try
        {
            // 快速提取消息信息（减少多次访问属性的开销）
            var clientId = eventArgs.ClientId;
            var topic = eventArgs.ApplicationMessage.Topic;
            var payloadSegment = eventArgs.ApplicationMessage.PayloadSegment;

            // 1. 基础校验（快速失败）：无效消息直接拒绝，减少后续处理
            if (string.IsNullOrWhiteSpace(clientId) ||
                string.IsNullOrWhiteSpace(topic) ||
                payloadSegment.Count == 0)
            {
                Logger.LogWarning("[TrackId:{TrackId}] 无效消息 | ClientId={0} | Topic={1}", trackId, clientId, topic);
                eventArgs.ProcessPublish = false;
                return;
            }

            // 2. 获取设备认证信息（从会话缓存，避免重复解析）
            // 设计原因：MQTT会话会缓存设备认证信息，无需每次重新解析，提升性能
            MqttAuthParams? authParams = eventArgs.SessionItems[AuthParamsSessionItemKey] as MqttAuthParams;
            if (authParams == null)
            {
                Logger.LogWarning("[TrackId:{TrackId}] 未找到认证信息 | ClientId={0}", trackId, clientId);
                eventArgs.ProcessPublish = false;
                return;
            }

            // 3. 设备信息校验：保证消息关联的设备信息完整
            if (string.IsNullOrWhiteSpace(authParams.ProductKey) ||
                string.IsNullOrWhiteSpace(authParams.DeviceName))
            {
                Logger.LogWarning("[TrackId:{TrackId}] 设备信息不完整 | ProductKey={0} | DeviceName={1}",
                    trackId, authParams.ProductKey, authParams.DeviceName);
                eventArgs.ProcessPublish = false;
                return;
            }

            // 4. 分级日志（性能优化：Debug级别才输出详细信息，减少日志开销）
            if (Logger.IsEnabled(LogLevel.Debug))
            {
                Logger.LogDebug(
                    "[接收设备消息] | [TrackId:{TrackId}] | 设备={0}/{1} | 主题={2} | 大小={3}B",
                    trackId, authParams.ProductKey, authParams.DeviceName, topic, payloadSegment.Count
                );
            }

            // 5. 构建事件对象（内存优化：AsSpan避免冗余数组复制）
            // 设计原因：payloadSegment.Array是完整数组，AsSpan仅取有效部分，减少内存拷贝
            var eto = new MqttClientPublishTopicEto
            {
                MqttTrackId = trackId,
                MqttClientId = clientId,
                MqttTopic = topic,
                MqttPayload = payloadSegment.Array!.AsSpan(payloadSegment.Offset, payloadSegment.Count).ToArray(),
                ProductKey = authParams.ProductKey,
                DeviceName = authParams.DeviceName,
                Timestamp = DateTime.UtcNow
            };

            // 6. 分支处理：启用批量优化则走批量队列，否则走单条发布
            if (CurrentIoTMqttOptions.PublishingOptimization.EnableOptimizations && _batchPublishQueue != null)
            {
                // 6.1 主题级限流检查（防止热点主题压垮系统）
                var topicThrottleLimit = CurrentIoTMqttOptions.PublishingOptimization.TopicBasedThrottling
                    .FirstOrDefault(kv => topic.StartsWith(kv.Key, StringComparison.OrdinalIgnoreCase)).Value;

                if (topicThrottleLimit > 0 && !IsWithinRateLimit(topic, topicThrottleLimit))
                {
                    Logger.LogWarning("[TrackId:{TrackId}] 主题限流 | Topic={0} | 限流阈值={1}条/秒",
                        trackId, topic, topicThrottleLimit);
                    _fallbackQueue.Enqueue(eto);
                    eventArgs.ProcessPublish = false;
                    return;
                }

                // 6.2 添加到批量发布队列（按主题分组）
                var topicQueue = _batchPublishQueue.GetOrAdd(topic, _ => new ConcurrentQueue<MqttClientPublishTopicEto>());
                topicQueue.Enqueue(eto);

                //+ 新增：更新最后入队时间
                UpdateTopicEnqueueTime(topic);

                // 6.3 达到阈值立即处理（减少消息延迟）
                if (topicQueue.Count >= CurrentIoTMqttOptions.PublishingOptimization.BatchPublishThreshold)
                {
                    await ProcessBatchQueueAsync(topicQueue).ConfigureAwait(false);
                    
                    // 处理完成后移除时间记录
                    _topicLastEnqueueTime.TryRemove(topic, out _);
                }

                eventArgs.ProcessPublish = true;
            }
            else
            {
                // 6. 核心处理：使用Polly组合策略（隔离+熔断保护）
                await GetCombinedPolicy().ExecuteAsync(async (context) =>
                {
                    context["Eto"] = eto;
                    await DistributedEventBus.PublishAsync(eto, onUnitOfWorkComplete: false, useOutbox: true)
                        .ConfigureAwait(false);
                }, new Context()).ConfigureAwait(false);

                Logger.LogDebug("[单条发布(非队列)] | [消息发布成功] -> [事件总线] [TrackId:{TrackId}] | Topic={0}", trackId, topic);
                eventArgs.ProcessPublish = true;
            }
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "[TrackId:{TrackId}] 处理MQTT消息失败", trackId);
            eventArgs.ProcessPublish = false;
        }
    }

    /// <summary>
    /// 速率限制检查（原有逻辑保留）
    /// </summary>
    private bool IsWithinRateLimit(string topic, int limit)
    {
        // 此处为原有实现，根据实际业务逻辑补充
        return true;
    }
    #endregion

    /// <summary>
    /// 释放资源（原有逻辑保留）
    /// </summary>
    public void Dispose()
    {
        _batchPublishCts?.Cancel();
        _retryLock?.Dispose();
        _batchProcessLock?.Dispose();
    }
}

```








 